# @package _global_
# make sure to include the above commented global setting!

train_tasks: 20
eval_tasks: 20
global_seed: 1


defaults:
  - /cl_dataset: permuted_mnist.yaml
  - /mtl_algorithm: joint_learning.yaml
  - /backbone: mlp.yaml
  - /optimizer: adam.yaml
  - /lr_scheduler: reduce_lr_on_plateau.yaml
  - /trainer: mps.yaml
  - /lightning_loggers: default.yaml
  - /callbacks: joint.yaml
  - /hydra: default.yaml
  - /misc: default.yaml

trainer: 
  max_epochs: 2

output_dir: outputs/joint_til_pmnist_finetuning/${misc.timestamp}


